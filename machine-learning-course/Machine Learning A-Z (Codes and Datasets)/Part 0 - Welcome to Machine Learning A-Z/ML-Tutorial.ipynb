{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df96b78e-bfdf-4d77-a1f0-7112fa9a35eb",
   "metadata": {},
   "source": [
    "# What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9801ce-bde3-45ad-ba1b-c95d22c6667c",
   "metadata": {},
   "source": [
    "Machine learning is a branch of artificial intelligence (AI) that focuses on developing algorithms and techniques that allow computers to learn and improve from experience without being explicitly programmed. In other words, it's about creating algorithms that can learn from data to make predictions, identify patterns, or make decisions.\n",
    "\n",
    "There are several types of machine learning approaches:\n",
    "\n",
    "1. **Supervised Learning:** In supervised learning, the algorithm is trained on labeled data, meaning the input data is paired with the correct output. The goal is for the algorithm to learn the mapping between inputs and outputs so that it can predict the correct output for new, unseen inputs.\n",
    "\n",
    "2. **Unsupervised Learning:** Unsupervised learning involves training the algorithm on unlabeled data, where the algorithm must find patterns or structures in the data on its own. Clustering and dimensionality reduction are common tasks in unsupervised learning.\n",
    "\n",
    "3. **Semi-Supervised Learning:** This combines aspects of supervised and unsupervised learning. Some of the data is labeled, but a large portion is unlabeled. The algorithm uses the labeled data to learn patterns and then applies that learning to the unlabeled data.\n",
    "\n",
    "4. **Reinforcement Learning:** In reinforcement learning, an agent learns to make decisions by interacting with an environment. It receives feedback in the form of rewards or penalties based on its actions, and its goal is to learn the optimal strategy to maximize cumulative rewards over time.\n",
    "\n",
    "Machine learning is applied in various domains, including image and speech recognition, natural language processing, recommendation systems, healthcare, finance, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd444dd6-7cf8-43a7-a8e1-86c1d7b32d77",
   "metadata": {},
   "source": [
    "# What is data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f2cfa-5e6a-4bd8-84c8-6e066093b499",
   "metadata": {},
   "source": [
    "Data science is an interdisciplinary field that combines techniques from statistics, mathematics, computer science, domain expertise, and other disciplines to extract knowledge and insights from structured and unstructured data. It involves collecting, cleaning, analyzing, and interpreting data to solve complex problems and make data-driven decisions.\n",
    "\n",
    "Here are some key components of data science:\n",
    "\n",
    "1. **Data Collection:** Data scientists collect data from various sources, such as databases, APIs, sensors, social media, and more. They may use tools like web scraping, data extraction techniques, or data acquisition systems to gather data.\n",
    "\n",
    "2. **Data Cleaning and Preprocessing:** Raw data often contains errors, missing values, inconsistencies, and noise. Data scientists clean and preprocess the data to ensure its quality and usability for analysis. This may involve tasks like imputation, outlier detection, normalization, and data transformation.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):** EDA involves visually exploring and summarizing the data to understand its characteristics, detect patterns, relationships, and outliers. Data visualization techniques, statistical analysis, and data mining methods are used during EDA.\n",
    "\n",
    "4. **Statistical Analysis and Modeling:** Data scientists use statistical techniques and machine learning algorithms to analyze data, build predictive models, identify trends, make forecasts, and derive insights. They select appropriate models based on the problem domain, data type, and objectives.\n",
    "\n",
    "5. **Machine Learning and AI:** Machine learning plays a significant role in data science, especially for tasks like classification, regression, clustering, anomaly detection, and recommendation systems. Data scientists train machine learning models on data to automate decision-making and generate predictions.\n",
    "\n",
    "6. **Data Interpretation and Communication:** After analyzing the data and deriving insights, data scientists communicate their findings to stakeholders through reports, dashboards, visualizations, and presentations. They explain complex technical concepts in a clear and understandable manner to support decision-making processes.\n",
    "\n",
    "Data science is used across various industries and domains, including healthcare, finance, marketing, e-commerce, cybersecurity, and more, to extract valuable insights, optimize processes, improve decision-making, and drive innovation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843de57e-083b-4e98-b070-d2f713b71910",
   "metadata": {},
   "source": [
    "# What is Deep learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37330cb9-f22b-4996-bf95-b7b168bc3cc5",
   "metadata": {},
   "source": [
    "Deep learning is a subset of machine learning that focuses on artificial neural networks and deep neural networks. These networks are inspired by the structure and function of the human brain, specifically the interconnected network of neurons that process and transmit information.\n",
    "\n",
    "Key characteristics of deep learning include:\n",
    "\n",
    "1. **Neural Networks:** Deep learning algorithms use neural networks, which are computational models composed of layers of interconnected nodes (neurons). Each node performs simple computations and passes the result to the next layer.\n",
    "\n",
    "2. **Deep Neural Networks (DNNs):** Deep learning models typically have multiple hidden layers between the input and output layers, allowing them to learn complex hierarchical representations of data. This depth of layers distinguishes deep learning from shallow neural networks.\n",
    "\n",
    "3. **Feature Learning:** Deep learning algorithms automatically learn hierarchical representations or features from the raw data. This means that the system can discover relevant features from the data itself, reducing the need for manual feature engineering.\n",
    "\n",
    "4. **Training with Big Data:** Deep learning models require large amounts of labeled data for training, as they learn to recognize patterns and make predictions based on examples. The availability of big data has contributed significantly to the success of deep learning.\n",
    "\n",
    "5. **Learning Representations:** Deep learning focuses on learning representations of data at multiple levels of abstraction. Lower layers might learn basic features like edges and textures, while higher layers learn more abstract features relevant to the task.\n",
    "\n",
    "6. **Applications:** Deep learning has been successfully applied to various tasks, including image and speech recognition, natural language processing, computer vision, recommendation systems, autonomous driving, healthcare diagnostics, and more.\n",
    "\n",
    "Popular deep learning architectures include Convolutional Neural Networks (CNNs) for image processing, Recurrent Neural Networks (RNNs) for sequence data, Generative Adversarial Networks (GANs) for generating new data, and Transformer models for natural language processing tasks.\n",
    "\n",
    "Deep learning has achieved remarkable performance in many domains, surpassing traditional machine learning approaches in tasks that involve large datasets and complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5e289-3daf-4e2e-aac3-56ec2e2da937",
   "metadata": {},
   "source": [
    "# What is artificial intelligence? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434cb86-dac4-4e82-8e6e-5b34507ea4bc",
   "metadata": {},
   "source": [
    "Artificial intelligence (AI) refers to the development of computer systems and algorithms that can perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, language understanding, and decision-making.\n",
    "\n",
    "Key components of artificial intelligence include:\n",
    "\n",
    "1. **Machine Learning:** Machine learning is a subset of AI that focuses on developing algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data. Supervised learning, unsupervised learning, and reinforcement learning are common types of machine learning approaches.\n",
    "\n",
    "2. **Deep Learning:** Deep learning is a subfield of machine learning that uses neural networks with multiple layers (deep neural networks) to learn complex representations of data. Deep learning has been particularly successful in tasks such as image and speech recognition, natural language processing, and robotics.\n",
    "\n",
    "3. **Natural Language Processing (NLP):** NLP is a branch of AI that deals with the interaction between computers and human languages. It involves tasks like language translation, sentiment analysis, text generation, speech recognition, and understanding and generating human-like responses.\n",
    "\n",
    "4. **Computer Vision:** Computer vision is another subfield of AI focused on enabling computers to interpret and understand visual information from the world, such as images and videos. Applications include object detection, image classification, facial recognition, and autonomous driving.\n",
    "\n",
    "5. **Robotics:** AI plays a crucial role in robotics by enabling robots to perceive their environment, make decisions, plan actions, and interact with humans and other machines. AI-powered robots are used in manufacturing, healthcare, agriculture, exploration, and various other domains.\n",
    "\n",
    "6. **Expert Systems:** Expert systems are AI systems that mimic the decision-making abilities of human experts in specific domains. These systems use knowledge bases and rules to provide recommendations, diagnoses, or solutions based on input data and expertise.\n",
    "\n",
    "AI technologies are widely used across industries, including healthcare, finance, education, transportation, entertainment, and cybersecurity, to automate tasks, improve efficiency, enhance decision-making, and create innovative products and services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ee4a1-2594-4421-a6d9-bd73ae3e6e6f",
   "metadata": {},
   "source": [
    "# What is Supervised Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58151a65-aace-4bf8-8429-79e91fb49bd8",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning where the algorithm is trained on a labeled dataset, meaning each input data point is associated with a corresponding output or target label. The goal of supervised learning is to learn the mapping or relationship between input features and target labels so that the algorithm can make predictions or decisions for new, unseen data.\n",
    "\n",
    "Here are the key characteristics and steps involved in supervised learning:\n",
    "\n",
    "1. **Labeled Data:** In supervised learning, the training dataset consists of labeled examples, where each example includes input features and the corresponding correct output or target label. For example, in a spam email classification task, the input features might be the email content, and the target labels would indicate whether each email is spam or not.\n",
    "\n",
    "2. **Training Phase:** During the training phase, the supervised learning algorithm learns from the labeled data to create a model that can predict the correct output based on new input data. The model's goal is to minimize the difference between its predictions and the actual labels in the training data.\n",
    "\n",
    "3. **Model Selection:** Supervised learning offers a variety of algorithms and models that can be used depending on the nature of the problem and the data. Common supervised learning algorithms include linear regression, logistic regression, decision trees, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.\n",
    "\n",
    "4. **Learning Process:** The learning process involves adjusting the model's parameters or weights based on the training data to improve its predictive accuracy. This process is often guided by an optimization algorithm that minimizes a loss function, such as mean squared error (MSE) for regression tasks or cross-entropy loss for classification tasks.\n",
    "\n",
    "5. **Evaluation:** After training the model, it is evaluated using a separate validation or test dataset to assess its performance and generalization ability. Metrics such as accuracy, precision, recall, F1 score, and mean absolute error (MAE) are commonly used to evaluate supervised learning models.\n",
    "\n",
    "6. **Prediction:** Once the model is trained and evaluated, it can be used to make predictions or classify new, unseen data based on the learned patterns and relationships from the training phase.\n",
    "\n",
    "Supervised learning is widely used in various applications, including but not limited to classification (e.g., spam detection, image recognition), regression (e.g., price prediction, demand forecasting), and ranking (e.g., recommendation systems, search engines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a6ff4-f0e1-4e24-bef5-43d47232446f",
   "metadata": {},
   "source": [
    "# What is Unsupervised learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571f3b2-9d4b-4b0c-a6b9-9a8952375c30",
   "metadata": {},
   "source": [
    "Unsupervised learning is a type of machine learning where the algorithm is trained on unlabeled data, meaning the input data does not have corresponding output labels or target values. The goal of unsupervised learning is to discover hidden patterns, structures, or relationships within the data without explicit guidance or supervision.\n",
    "\n",
    "Here are the key characteristics and concepts related to unsupervised learning:\n",
    "\n",
    "1. **Unlabeled Data:** In unsupervised learning, the training dataset consists of input data only, without any associated output labels or target values. This data is typically raw or unstructured, and the algorithm's task is to find meaningful patterns or groupings within it.\n",
    "\n",
    "2. **Clustering:** Clustering is a common task in unsupervised learning where the algorithm groups similar data points together into clusters or segments based on their inherent characteristics or features. Popular clustering algorithms include k-means clustering, hierarchical clustering, and DBSCAN.\n",
    "\n",
    "3. **Dimensionality Reduction:** Dimensionality reduction techniques aim to reduce the number of features or variables in the data while preserving important information. Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE) are examples of dimensionality reduction methods used in unsupervised learning.\n",
    "\n",
    "4. **Anomaly Detection:** Anomaly detection, also known as outlier detection, involves identifying rare or unusual data points that deviate significantly from the majority of the data. Unsupervised learning algorithms can detect anomalies by modeling the normal behavior of the data and flagging instances that fall outside this model.\n",
    "\n",
    "5. **Association Rule Learning:** Association rule learning is another aspect of unsupervised learning where the algorithm discovers interesting relationships or associations between variables in the data. Apriori and FP-growth are popular algorithms for mining association rules in transactional data.\n",
    "\n",
    "6. **Autoencoders:** Autoencoders are a type of neural network architecture used in unsupervised learning for feature learning and data compression. They learn to reconstruct the input data from a compressed representation, capturing meaningful features in the process.\n",
    "\n",
    "7. **Generative Models:** Generative models in unsupervised learning aim to learn the underlying distribution of the data and generate new samples that are similar to the original data. Examples include Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs).\n",
    "\n",
    "Unsupervised learning is valuable for exploratory data analysis, pattern recognition, data preprocessing, anomaly detection, and generating insights from unlabeled datasets. It is used in various domains, including customer segmentation, market basket analysis, fraud detection, image clustering, and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc2f40-d1ae-4dde-884e-5baffc56973d",
   "metadata": {},
   "source": [
    "# What is Classification Analysis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f17564-cd24-41c3-bec2-7b47e1955867",
   "metadata": {},
   "source": [
    "Classification analysis, also known as classification modeling or classification algorithms, is a machine learning technique used to categorize data points into predefined classes or categories based on their features. It is a supervised learning approach where the algorithm learns from labeled training data to make predictions about the class labels of new, unseen data points.\n",
    "\n",
    "Here are the key concepts and components of classification analysis:\n",
    "\n",
    "1. **Classes or Categories:** In classification analysis, the target variable or dependent variable is categorical, meaning it represents discrete classes or categories. For example, classes could be \"spam\" or \"not spam\" for email classification, \"positive\" or \"negative\" for sentiment analysis, or different types of diseases in medical diagnosis.\n",
    "\n",
    "2. **Features or Predictors:** Features, also called predictors or independent variables, are the input variables used by the classification algorithm to make predictions about the class labels. These features can be numeric, categorical, or a combination of both.\n",
    "\n",
    "3. **Classification Models:** Classification models are algorithms that learn patterns and relationships in the training data to classify new instances into one of the predefined classes. Common classification algorithms include:\n",
    "\n",
    "   - **Logistic Regression:** Despite its name, logistic regression is used for binary classification tasks. It models the probability of an instance belonging to a particular class using a logistic function.\n",
    "   \n",
    "   - **Decision Trees:** Decision tree classifiers partition the feature space into regions based on if-else decision rules, forming a tree-like structure that can make categorical predictions.\n",
    "   \n",
    "   - **Random Forest:** Random forest is an ensemble learning technique that combines multiple decision trees to improve predictive accuracy and reduce overfitting.\n",
    "   \n",
    "   - **Support Vector Machines (SVM):** SVMs find the optimal hyperplane that separates different classes in the feature space, maximizing the margin between classes.\n",
    "   \n",
    "   - **K-Nearest Neighbors (KNN):** KNN classifies instances based on the majority class among their k nearest neighbors in the feature space.\n",
    "   \n",
    "   - **Naive Bayes:** Naive Bayes classifiers are based on Bayes' theorem and assume independence between features. They are particularly effective for text classification tasks.\n",
    "   \n",
    "   - **Neural Networks:** Neural network classifiers, such as feedforward neural networks or convolutional neural networks (CNNs), learn complex relationships in the data through layers of interconnected neurons.\n",
    "\n",
    "4. **Training and Testing:** In classification analysis, the algorithm is trained on a labeled training dataset, where each instance has known class labels. After training, the model is evaluated using a separate test dataset to assess its performance, accuracy, precision, recall, F1 score, and other metrics.\n",
    "\n",
    "5. **Decision Boundaries:** Classification models create decision boundaries in the feature space that separate different classes. The shape and complexity of these decision boundaries depend on the algorithm and the nature of the data.\n",
    "\n",
    "6. **Model Evaluation:** Model evaluation involves assessing the performance of the classification model using metrics such as accuracy, precision, recall, F1 score, confusion matrix, ROC curve, and AUC-ROC (Area Under the ROC Curve).\n",
    "\n",
    "Classification analysis is applied in various domains, including but not limited to:\n",
    "- Email spam detection\n",
    "- Sentiment analysis\n",
    "- Image classification\n",
    "- Fraud detection\n",
    "- Medical diagnosis\n",
    "- Customer segmentation\n",
    "- Predictive maintenance\n",
    "- Risk assessment\n",
    "- Churn prediction\n",
    "- Credit scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8a378-63b1-4fc4-b961-6ba34e133eb1",
   "metadata": {},
   "source": [
    "# What is Regression Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645817f2-908b-4516-bdbe-25e848e3b09a",
   "metadata": {},
   "source": [
    "Regression analysis is a statistical method used to examine the relationship between a dependent variable (target variable) and one or more independent variables (predictor variables). It is commonly used for predictive modeling and understanding the impact of independent variables on the dependent variable.\n",
    "\n",
    "Here are the key concepts and components of regression analysis:\n",
    "\n",
    "1. **Dependent Variable:** The dependent variable, also known as the response variable or target variable, is the variable that you want to predict or explain. It is typically denoted as \\( Y \\) in regression analysis.\n",
    "\n",
    "2. **Independent Variables:** Independent variables, also called predictor variables or features, are the variables that are used to predict or explain variations in the dependent variable. They are denoted as \\( X_1, X_2, \\ldots, X_n \\) in regression analysis, where \\( n \\) is the number of independent variables.\n",
    "\n",
    "3. **Regression Models:** Regression models describe the relationship between the dependent variable and independent variables. There are different types of regression models, including:\n",
    "\n",
    "   - **Linear Regression:** Linear regression models assume a linear relationship between the dependent variable and independent variables. The simple linear regression model has one independent variable, while multiple linear regression involves multiple independent variables.\n",
    "   \n",
    "   - **Polynomial Regression:** Polynomial regression models capture nonlinear relationships by using polynomial functions of the independent variables.\n",
    "   \n",
    "   - **Logistic Regression:** Logistic regression is used for binary classification tasks, where the dependent variable is categorical (e.g., yes/no, true/false). It models the probability of a binary outcome based on the independent variables.\n",
    "   \n",
    "   - **Nonlinear Regression:** Nonlinear regression models capture nonlinear relationships between variables using nonlinear functions, such as exponential, logarithmic, or sigmoidal functions.\n",
    "\n",
    "4. **Regression Equation:** The regression equation represents the mathematical relationship between the dependent variable and independent variables. In simple linear regression, the equation is of the form \\( Y = \\beta_0 + \\beta_1 X_1 \\), where \\( \\beta_0 \\) is the intercept and \\( \\beta_1 \\) is the coefficient for \\( X_1 \\).\n",
    "\n",
    "5. **Fitting the Model:** Regression analysis involves fitting the regression model to the training data by estimating the coefficients (parameters) that best describe the relationship between the variables. This is often done using methods like least squares estimation, maximum likelihood estimation, or gradient descent.\n",
    "\n",
    "6. **Model Evaluation:** After fitting the model, it is evaluated using metrics such as R-squared (coefficient of determination), mean squared error (MSE), root mean squared error (RMSE), and adjusted R-squared. These metrics assess how well the model fits the data and makes predictions.\n",
    "\n",
    "Regression analysis is widely used in various fields, including economics, finance, social sciences, healthcare, and engineering, for tasks such as predicting sales, estimating risk factors, analyzing trends, and making forecasts based on historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69aa6b1-3e9c-4a3f-9daf-1d3305b67295",
   "metadata": {},
   "source": [
    "# What is cluster analysis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b103b91-6ec7-4168-98ca-1b0a94309303",
   "metadata": {},
   "source": [
    "Cluster analysis, also known as clustering, is a technique used in unsupervised learning to group similar data points or objects into clusters or clusters based on their characteristics or features. The goal of cluster analysis is to discover inherent patterns, structures, or natural groupings in the data without prior knowledge of class labels.\n",
    "\n",
    "Here are the key concepts and components of cluster analysis:\n",
    "\n",
    "1. **Clustering Algorithms:** Cluster analysis involves using clustering algorithms to partition the data into clusters based on similarity or distance measures between data points. Common clustering algorithms include:\n",
    "\n",
    "   - **K-means Clustering:** K-means is a centroid-based clustering algorithm that partitions the data into k clusters, where each cluster is represented by its centroid (mean). It minimizes the sum of squared distances between data points and their respective cluster centroids.\n",
    "   \n",
    "   - **Hierarchical Clustering:** Hierarchical clustering creates a hierarchy of clusters by iteratively merging or splitting clusters based on proximity measures. It can be agglomerative (bottom-up) or divisive (top-down).\n",
    "   \n",
    "   - **Density-based Clustering:** Density-based clustering algorithms, such as DBSCAN (Density-Based Spatial Clustering of Applications with Noise), group together data points that are closely packed in high-density regions and separate outliers as noise.\n",
    "   \n",
    "   - **Expectation-Maximization (EM) Clustering:** EM clustering is used for modeling data with probabilistic distributions, such as Gaussian Mixture Models (GMM). It estimates the parameters of the distributions and assigns data points to clusters based on maximum likelihood.\n",
    "   \n",
    "   - **Self-Organizing Maps (SOM):** SOM is a neural network-based clustering technique that maps high-dimensional data onto a lower-dimensional grid, preserving topological relationships between data points.\n",
    "\n",
    "2. **Distance or Similarity Measures:** Cluster analysis relies on distance or similarity measures to quantify the similarity between data points or clusters. Common distance measures include Euclidean distance, Manhattan distance, cosine similarity, and Jaccard similarity, depending on the data type and domain.\n",
    "\n",
    "3. **Cluster Evaluation:** Evaluating the quality and validity of clusters is an important aspect of cluster analysis. Metrics such as silhouette score, Davies-Bouldin index, Dunn index, and within-cluster sum of squares (WCSS) are used to assess cluster compactness, separation, and cohesion.\n",
    "\n",
    "4. **Interpretation and Visualization:** After clustering, interpreting and visualizing the results are essential for understanding the structure of the data and identifying meaningful patterns. Techniques such as scatter plots, dendrograms, silhouette plots, and cluster profiling can aid in visualization and interpretation.\n",
    "\n",
    "5. **Applications of Cluster Analysis:** Cluster analysis is applied in various domains and tasks, including:\n",
    "\n",
    "   - Customer segmentation and market segmentation\n",
    "   - Anomaly detection and outlier identification\n",
    "   - Image segmentation and object recognition\n",
    "   - Document clustering and text mining\n",
    "   - Pattern recognition and data compression\n",
    "   - Recommender systems and personalized marketing\n",
    "   - Biological data analysis and genomics\n",
    "   - Spatial data analysis and geographical clustering\n",
    "\n",
    "Cluster analysis helps uncover hidden structures in data, improve decision-making, identify trends and patterns, and support exploratory data analysis in diverse fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa97a3-da5e-4bc5-b4fa-7dc673bfff51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
